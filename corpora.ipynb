{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b1e888d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import pytesseract\n",
    "from tempfile import TemporaryDirectory\n",
    "from PIL import Image\n",
    "from pathlib import Path \n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "\n",
    "pdf = Path()/\"bini_dict.pdf\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ca95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf2img(pdf_path):\n",
    "    \"\"\"\n",
    "    Converts the PDF to images and writes the OCR output to a single text file.\n",
    "    \"\"\"\n",
    "    output_folder = Path(\"output_folder\")\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    with TemporaryDirectory() as tmp:\n",
    "        storage = Path(tmp)\n",
    "        convert_from_path(\n",
    "            pdf_path=Path(pdf_path),\n",
    "            output_folder=storage,\n",
    "            fmt='png',\n",
    "            single_file=False,\n",
    "            first_page=19,\n",
    "            thread_count=4, \n",
    "        )\n",
    "\n",
    "        with open(output_folder/\"output_file.txt\", \"w\") as f:\n",
    "            for x in sorted(storage.glob(\"*.png\")): \n",
    "                text = pytesseract.image_to_string(Image.open(x)) # after training the model, use lang=['eng', 'bini'] as an argument\n",
    "                f.write(text + \"\\n\\n\")  # Add newlines between pages\n",
    "                # fix: pages of the file ebing written get scattered, find out why\n",
    "\n",
    "\n",
    "# read_pdf2img(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb3932",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TXT  = \"output_folder/output_file.txt\"   # path to your text file\n",
    "OUTPUT_CSV = \"bini_pairs_2.csv\"  # output csv filename\n",
    "\n",
    "def normalize_block(block: str) -> str:\n",
    "    \"\"\"Fix hyphenated line-breaks and join lines with spaces.\"\"\"\n",
    "    lines = [ln.strip() for ln in block.splitlines()]\n",
    "    combined = []\n",
    "    for ln in lines:\n",
    "        if not combined:\n",
    "            combined.append(ln)\n",
    "        else:\n",
    "            if combined[-1].endswith(\"-\"):\n",
    "                combined[-1] = combined[-1][:-1] + ln  # remove trailing '-' and glue\n",
    "            else:\n",
    "                combined.append(ln)\n",
    "    return \" \".join(combined)\n",
    "\n",
    "\n",
    "def extract_pairs(text: str):\n",
    "    # 1) Split the file into blocks separated by blank lines\n",
    "    blocks = [b.strip() for b in re.split(r\"\\n\\s*\\n\", text) if b.strip()]\n",
    "\n",
    "    rows = []\n",
    "    for block in blocks:\n",
    "        nb = normalize_block(block)\n",
    "        # Skip headers\n",
    "        if nb.upper().startswith(\"BINI DICTIONARY\"):\n",
    "            continue\n",
    "\n",
    "        # 2) Capture the headword = first non-space token at start of block\n",
    "        m = re.match(r\"^\\s*(?P<head>\\S+)\\s*(?P<rest>.*)$\", nb)\n",
    "        if not m:\n",
    "            continue\n",
    "        head = m.group(\"head\").strip()\n",
    "        rest = m.group(\"rest\").strip()\n",
    "\n",
    "        # 3) If a pronunciation bracket immediately follows the headword, drop it\n",
    "        rest = re.sub(r\"^\\[[^\\]]+\\]\\s*\", \"\", rest)\n",
    "\n",
    "        # 4) Tidy leading separators (| : ; , . dashes) before the gloss\n",
    "        rest = re.sub(r\"^[\\s\\|\\:\\;\\,\\.\\-–—]+\", \"\", rest)\n",
    "\n",
    "        rows.append((head, rest))\n",
    "    return rows\n",
    "\n",
    "\n",
    "def main():\n",
    "    with open(INPUT_TXT, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    rows = extract_pairs(text)\n",
    "\n",
    "    with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as out:\n",
    "        w = csv.writer(out)\n",
    "        w.writerow([\"bini\", \"english\"])\n",
    "        w.writerows(rows)\n",
    "\n",
    "    print(f\"Done. Wrote {len(rows)} rows to {OUTPUT_CSV}\")\n",
    "\n",
    "\n",
    "# tested but still needs some tuning. post csv making, there should be some cleaning done via pandas to maintain the intergrity of the bnin words,\n",
    "# likely well map the special characters to the mistaken characters\n",
    "\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path(\"\")\n",
    "df = pd.read_csv(data)\n",
    "df.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
