{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e888d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordninja\n",
    "import re\n",
    "import csv\n",
    "import pytesseract\n",
    "from tempfile import TemporaryDirectory\n",
    "from PIL import Image\n",
    "from pathlib import Path \n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "\n",
    "pdf = Path()/\"bini_dict.pdf\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02ca95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf2img(pdf_path):\n",
    "    \"\"\"\n",
    "    Converts the PDF to images and writes the OCR output to a single text file.\n",
    "    \"\"\"\n",
    "    output_folder = Path(\"output_folder\")\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    with TemporaryDirectory() as tmp:\n",
    "        storage = Path(tmp)\n",
    "        convert_from_path(\n",
    "            pdf_path=Path(pdf_path),\n",
    "            output_folder=storage,\n",
    "            fmt='png',\n",
    "            single_file=False,\n",
    "            first_page=19,\n",
    "            thread_count=4, \n",
    "        )\n",
    "\n",
    "        with open(output_folder/\"output_file.txt\", \"w\") as f:\n",
    "            for x in sorted(storage.glob(\"*.png\")): \n",
    "                text = pytesseract.image_to_string(Image.open(x)) # after training the model, use lang=['eng', 'bini'] as an argument\n",
    "                f.write(text + \"\\n\\n\")  # Add newlines between pages\n",
    "                # fix: pages of the file ebing written get scattered, find out why\n",
    "\n",
    "# read_pdf2img(pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2beb3932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote 4347 rows to bini_pairs_2.csv\n"
     ]
    }
   ],
   "source": [
    "# def clean_text():\n",
    "#     \"\"\"\n",
    "#     extract bini word and definitions, clean both separately and store the output as csv\n",
    "#     \"\"\"\n",
    "#     text = Path()/\"output_folder/output_file.txt\"\n",
    "\n",
    "# NOT TESTED, I DO NOT KNOW WHAT THIS CODE DOES AT ALL, but by all means look into it - kinged\n",
    "\n",
    "INPUT_TXT  = \"output_folder/output_file.txt\"   # path to your text file\n",
    "OUTPUT_CSV = \"bini_pairs_2.csv\"  # output csv filename\n",
    "\n",
    "def normalize_block(block: str) -> str:\n",
    "    \"\"\"Fix hyphenated line-breaks and join lines with spaces.\"\"\"\n",
    "    lines = [ln.strip() for ln in block.splitlines()]\n",
    "    combined = []\n",
    "    for ln in lines:\n",
    "        if not combined:\n",
    "            combined.append(ln)\n",
    "        else:\n",
    "            if combined[-1].endswith(\"-\"):\n",
    "                combined[-1] = combined[-1][:-1] + ln  # remove trailing '-' and glue\n",
    "            else:\n",
    "                combined.append(ln)\n",
    "    return \" \".join(combined)\n",
    "\n",
    "def extract_pairs(text: str):\n",
    "    # 1) Split the file into blocks separated by blank lines\n",
    "    blocks = [b.strip() for b in re.split(r\"\\n\\s*\\n\", text) if b.strip()]\n",
    "\n",
    "    rows = []\n",
    "    for block in blocks:\n",
    "        nb = normalize_block(block)\n",
    "        # Skip headers\n",
    "        if nb.upper().startswith(\"BINI DICTIONARY\"):\n",
    "            continue\n",
    "\n",
    "        # 2) Capture the headword = first non-space token at start of block\n",
    "        m = re.match(r\"^\\s*(?P<head>\\S+)\\s*(?P<rest>.*)$\", nb)\n",
    "        if not m:\n",
    "            continue\n",
    "        head = m.group(\"head\").strip()\n",
    "        rest = m.group(\"rest\").strip()\n",
    "\n",
    "        # 3) If a pronunciation bracket immediately follows the headword, drop it\n",
    "        rest = re.sub(r\"^\\[[^\\]]+\\]\\s*\", \"\", rest)\n",
    "\n",
    "        # 4) Tidy leading separators (| : ; , . dashes) before the gloss\n",
    "        rest = re.sub(r\"^[\\s\\|\\:\\;\\,\\.\\-–—]+\", \"\", rest)\n",
    "\n",
    "        rows.append((head, rest))\n",
    "    return rows\n",
    "\n",
    "def main():\n",
    "    with open(INPUT_TXT, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    rows = extract_pairs(text)\n",
    "\n",
    "    with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as out:\n",
    "        w = csv.writer(out)\n",
    "        w.writerow([\"bini\", \"english\"])\n",
    "        w.writerows(rows)\n",
    "\n",
    "    print(f\"Done. Wrote {len(rows)} rows to {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3abcdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "been given tone-marks of their own in noun-headings, but not in\n",
      "grammatical elements like (e)t-, (e)v-, etc., nor in sentences.\n",
      "\n",
      "The sign > has occasionally been used where a word had to be broken\n",
      "up at the end of a line, for purely technical reasons.\n",
      "\n",
      "ORDER AND Form OF ITEMS\n",
      "\n",
      "The letters follow one another in the following order: a, b, d, e, ¢, f,\n",
      "g, gb, x, h, i,k, kp, 1, m, n, nw, ny, 0, 9, p, r, rh, f, f, s, t, u, v, 6, w, x, y, z.\n",
      "\n",
      "In the case of words differing in tone only, the items with high tones\n",
      "are placed first, then those containing both high and low (or mid) tones,\n",
      "then the words with low tones only, and last those with rises or falls.\n",
      "\n",
      "Unnasalised vowels have no precedence over nasalised ones, except\n",
      "where the tones are the same.\n",
      "\n",
      "Nouns beginning with e-, i.e. an e- prefix which occurs mostly in a\n",
      "\n",
      "context and is often not pronounced when isolated, are found under the\n",
      "vowel e, but grammatical elements like (e)n-, (e)t-, etc. are entered\n",
      "under the appropriate consonant.\n",
      "Entirely different items with the same phonetic and tonal form are\n",
      "differentiated by means of numbers. Different meanings that may be\n",
      "explained as semantic developments of one word are marked with\n",
      "bracketed numbers within the same item. Different meanings brought\n",
      "about by the addition of a noun, for example, in the genitive or object-\n",
      "relationship are usually not numbered.\n",
      "\n",
      "In the case of verbs, the verbal combinations are given before the\n",
      "verb-noun combinations. In the verb-noun combinations the two ele-\n",
      "ments have been joined where they are followed by an object, or if\n",
      "there is no further object, e.g. in gb-ovo [ \"] to be jealous, ogb-ovote[ \"J\n",
      "she is jealous of me, but the two elements have been kept separate\n",
      "when an object is put between them, e.g. in gbe [°] avo[ '] to make\n",
      "somebody jealous, ogbe 6-5vo [|] it makes me jealous. The tones of\n",
      "the imperfect forms have been used in the headings and sub-headings,\n",
      "but in the case of verbal combinations, each verb has been given its\n",
      "independent tone, irrespective of tonal interrelations in actual speech.\n",
      "In sentences and other illustrative material, however, the author has\n",
      "tried to reproduce the actual intonation of his informant (nearly always\n",
      "H. G. Amadasu). |\n",
      "\n",
      "Inverted commas have been used for the following purposes:\n",
      "\n",
      "(1) In single words or short expressions occurring in the English\n",
      "equivalent aiter the heading, they denote that the word or expression\n",
      "in question is “coastal English’’, i.e. either Pidgin-English or a peculiar\n",
      "usage of English in the speech of the informant.\n",
      "\n",
      "(2) In the translations of sentences, idioms, and explanatory notes,\n",
      "inverted commas denote either a literal translation which is not good\n",
      "English (and which may be followed by a free translation), or a quotation.\n",
      "\n",
      "xV\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text2 = pytesseract.image_to_string(\"/home/kinged/codes/dala/group_a/bini_pdf_as_img/test.png0001-015.png\")\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b67f3ff",
   "metadata": {},
   "source": [
    "^\\n\\w+ - first word that comes after a newlin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e8d7da",
   "metadata": {},
   "source": [
    "to deal with these special character translations you can get their greek counterparts and combinations from the unicode websites, convert them to hex values and then do the combinations and store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unicodes = \"/home/kinged/codes/dala/group_a/bini_unicode_map.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6265837a",
   "metadata": {},
   "source": [
    "a, b, d, e, chr(8455), f, g, gb, chr(), h, i, k, kp, l, m, n, nw, ny, o, chr(), p, r, rh, chr(), chr(), s, t, u, v, chr(965), w, x, y, z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d6d1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "υ\n",
      "GREEK SMALL LETTER UPSILON\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "# char = chr(949)\n",
    "# char = chr(8455)\n",
    "# char = 965\n",
    "char = 965\n",
    "char = 965\n",
    "char = 965\n",
    "print(chr(char))\n",
    "print(unicodedata.name(chr(char)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2bfc276f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a b d e ε ↄ υ\n"
     ]
    }
   ],
   "source": [
    "print(\"a\", \"b\", \"d\", \"e\", chr(949), chr(8580), chr(965))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ee22be91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x3c5 0x7e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'υ̃'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unicodedata.name(\"\\u2184\")\n",
    "# ord(\"\\u2184\")\n",
    "\n",
    "upsilon = unicodedata.lookup(\"greek small letter upsilon\")\n",
    "\n",
    "n = hex(965)\n",
    "u = hex(126)\n",
    "print(n, u)\n",
    "\n",
    "\"\\u03c5\\u0303\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
